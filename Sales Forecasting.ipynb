{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading necessary libraries\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the datasets\n",
    "\n",
    "train = pd.read_csv('train.csv', encoding = 'latin-1')\n",
    "test = pd.read_csv('test.csv', encoding = 'latin-1')\n",
    "store = pd.read_csv('store.csv', encoding = 'latin-1')\n",
    "\n",
    "print(\"\\n Train dataset dimensions: \", train.shape)\n",
    "print(\"\\n Test dataset dimensions: \", test.shape)\n",
    "print(\"\\n Store dataset dimensions: \", store.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "store.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Sales_per_customer'] = train['Sales']/train['Customers']\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[(train['Open'] == 0) & (train['Sales'] == 0)].shape\n",
    "# i.e., of the 172869 records, 172817 records have empty sales and the store status is closed. \n",
    "# removing these records from the analysis would be beneficial to avoid data skewness - 10% of total records\n",
    "\n",
    "# For the remaining 52 records, the sales numbers are still 0 \n",
    "# Will be dropping those records as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train[(train['Open'] != 0) & (train['Sales'] == 0)].shape\n",
    "df = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[(train['Open'] != 0) & (train['Sales'] != 0)]\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train['Sales'] != 0]\n",
    "\n",
    "print(np.mean(train.Sales))\n",
    "print(np.median(train.Sales))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(store.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace competitor distance information with median value - outliers not sure\n",
    "# Replace promo relevant information and competition open informations with 0\n",
    "\n",
    "store['CompetitionDistance'].fillna(store['CompetitionDistance'].median(), inplace = True)\n",
    "store.fillna(0, inplace = True)\n",
    "\n",
    "store.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining both train and store information dataset\n",
    "\n",
    "train_combined = pd.merge(train, store, how = 'inner', on = 'Store')\n",
    "train_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For ARIMA forecasting - considering a store from the dataset\n",
    "arima_train = train_combined.copy()\n",
    "arima_train = arima_train.set_index('Date')\n",
    "\n",
    "arima_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store85_sample = arima_train[arima_train.Store == 85].Sales\n",
    "store85_sample = store85_sample.sort_index(axis = 0)\n",
    "store85_sample.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store85_sample.index = pd.to_datetime(store85_sample.index)\n",
    "store85_sample.resample('MS').mean().plot(figsize = (25,10))\n",
    "plt.show()\n",
    "\n",
    "# from the plot, we observe some distibguishable patterns - like seasonality pattern i.e.,\n",
    "# the sales are always low at the beginning of the year \n",
    "# tend to have a peak just before the year end\n",
    "# and sales fall low at the year end\n",
    "\n",
    "# Also, we obseve an upward trend within any single year around the mid of the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store85_sample.index.min()\n",
    "store85_sample.index.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the data - \n",
    "# using time-series decomposition that allows us to decompose our time series data into 3 distinct components:\n",
    "# Trend, Seasonality and noise\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from pylab import rcParams\n",
    "\n",
    "rcParams['figure.figsize'] = 20,12\n",
    "\n",
    "decomposition = sm.tsa.seasonal_decompose(store85_sample, model = 'additive')\n",
    "fig = decomposition.plot()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# applying ARIMA\n",
    "import itertools\n",
    "\n",
    "p = range(10,12)\n",
    "d = q = range(0,2)\n",
    "pdq = list(itertools.product(p,d,q))\n",
    "\n",
    "sp = sd = sq = range(0,3)\n",
    "seasonal_pdq = [(x[0],x[1],x[2],12) for x in (list(itertools.product(sp,sd,sq)))]\n",
    "\n",
    "for param in pdq:\n",
    "    for param_seasonal in seasonal_pdq:\n",
    "        try:\n",
    "            mod = sm.tsa.statespace.SARIMAX(store85_sample, order = param, \n",
    "                                           seasonal_order = param_seasonal,\n",
    "                                           enforce_stationarity = False,\n",
    "                                           enforce_invertibility = False)\n",
    "            results = mod.fit()\n",
    "            print('ARIMA{}x{}12 - AIC : {}'.format(param, param_seasonal,results.aic))\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the above output lowet AIC value is for - \n",
    "# Considering SARMIAX(11,1,0)x(2,1,0,12)\n",
    "\n",
    "model = sm.tsa.statespace.SARIMAX(store85_sample, order = (11,1,0), \n",
    "                                                  seasonal_order = (2,1,0,12),\n",
    "                                                  enforce_stationarity = False,\n",
    "                                                  enforce_invertibility = False)\n",
    "results = model.fit()\n",
    "\n",
    "print(results.aic)\n",
    "\n",
    "print(results.summary().tables[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model diagnostics - to investigate any unusual behavior. \n",
    "results.plot_diagnostics(figsize=(20,10))\n",
    "plt.show()\n",
    "\n",
    "# Results - not perfect but model residues are nearly normally distributed and same is suggested by the QQ plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validating forecasts:\n",
    "from datetime import datetime\n",
    "pred = results.get_prediction(start = pd.to_datetime('2015-01-01')) #, dynamic = 'False')\n",
    "pred_ci = pred.conf_int()\n",
    "\n",
    "ax = store85_sample['2013':].plot(label = 'observed')\n",
    "\n",
    "pred.predicted_mean.plot(ax = ax, label = 'One-step ahead Forecast', alpha = 0.8, figsize = (20,8))\n",
    "\n",
    "ax.fill_between(pred_ci.index, pred_ci.iloc[:,0], pred_ci.iloc[:,1], color = 'k', alpha = 0.2)\n",
    "\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Store 85 Sales')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_forecasted = pred.predicted_mean\n",
    "y_truth = store85_sample['2015-01-01':]\n",
    "\n",
    "mse = ((y_forecasted - y_truth) ** 2).mean()\n",
    "\n",
    "print('The Mean Squared Error is: {}'.format(round(mse,2)))\n",
    "\n",
    "print('The Root Mean Squared Error is: {}'.format(round(np.sqrt(mse),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Producing and visualizing forecasts \n",
    "\n",
    "pred_uc = results.get_forecast(steps = 100)\n",
    "pred_ci = pred_uc.conf_int()\n",
    "\n",
    "ax = store85_sample.plot(label = 'observed', figsize = (20,8))\n",
    "\n",
    "pred_uc.predicted_mean.plot(ax = ax, label = 'Forecast')\n",
    "\n",
    "ax.fill_between(pred_ci.index, pred_ci.iloc[:,0], pred_ci.iloc[:,1], color = 'k', alpha = 0.25)\n",
    "\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Store 85 Sales')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series forecasting using Prophet\n",
    "# In 2017, Facebook released a forecasting tool Prophet designed for analyzing time series data that display patterns on \n",
    "# different time scales such as - yearly, weekly, daily\n",
    "# It also has advanced capabilities for modeling the effect of holidats on time series and implementing custom changepoints.\n",
    "\n",
    "from fbprophet import Prophet\n",
    "\n",
    "store85_sample_df = train_combined[train_combined.Store == 85][['Date','Sales']]\n",
    "store85_sample_df.rename(columns = {'Date': 'ds','Sales':'y'}, inplace = True)\n",
    "store85_sample_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet_model = Prophet(interval_width = 0.95)\n",
    "prophet_model.fit(store85_sample_df)\n",
    "\n",
    "forecast = prophet_model.make_future_dataframe(periods = 12, freq = 'MS')\n",
    "forecast = prophet_model.predict(forecast)\n",
    "\n",
    "plt.figure(figsize = (30,8))\n",
    "prophet_model.plot(forecast, xlabel = 'Date', ylabel = 'Store 85 Sales')\n",
    "plt.title('Store 85 Sales Forecast using Prophet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Regression models - \n",
    "# Multiple Linear Regression, SVR, Decision tree, Random Forest, XGB\n",
    "# Regularization methods - L1 , L2 regression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
